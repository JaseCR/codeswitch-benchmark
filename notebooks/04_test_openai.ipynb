{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OpenAI Adapter\n",
    "\n",
    "This notebook tests the OpenAI adapter with different configurations for code-switching analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key: True\n"
     ]
    }
   ],
   "source": [
    "# Setup: imports and environment\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import our adapter\n",
    "from adapters.openai_adapter import OpenAIAdapter\n",
    "\n",
    "# Verify that your key loaded correctly\n",
    "print(\"OpenAI key:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI adapter initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI adapter\n",
    "openai_adapter = OpenAIAdapter(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",  # Cost-effective model\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"OpenAI adapter initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Response: None\n"
     ]
    }
   ],
   "source": [
    "# Test basic generation\n",
    "test_prompt = \"Paraphrase this sentence without changing its meaning: He finna go to the store.\"\n",
    "\n",
    "response = openai_adapter.generate_response(test_prompt)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with system prompt for better code-switching analysis\n",
    "system_prompt = \"\"\"You are a linguist analyzing code-switching behavior. \n",
    "Your task is to preserve the dialectal style and cultural context while \n",
    "paraphrasing or continuing text. Maintain the same linguistic variety \n",
    "and register as the input.\"\"\"\n",
    "\n",
    "user_prompt = \"Paraphrase this AAVE sentence: He finna go to the store. You sliding?\"\n",
    "\n",
    "response = openai_adapter.generate_with_system_prompt(system_prompt, user_prompt)\n",
    "print(\"Response with system prompt:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple candidates\n",
    "candidates = openai_adapter.generate_multiple_candidates(\n",
    "    \"Continue this Spanglish sentence: Vamos later, it's muy close to la tienda.\",\n",
    "    num_candidates=3\n",
    ")\n",
    "\n",
    "print(\"Multiple candidates:\")\n",
    "for i, candidate in enumerate(candidates, 1):\n",
    "    print(f\"{i}. {candidate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different temperature settings\n",
    "temperatures = [0.2, 0.5, 0.8]\n",
    "prompt = \"Explain this British English phrase: 'We're off on holiday next week, fancy it?'\"\n",
    "\n",
    "print(\"Testing different temperature settings:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for temp in temperatures:\n",
    "    openai_adapter.update_config(temperature=temp)\n",
    "    response = openai_adapter.generate_response(prompt)\n",
    "    print(f\"\\nüå°Ô∏è Temperature {temp}:\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with retry mechanism\n",
    "print(\"Testing retry mechanism:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "response = openai_adapter.generate_with_retry(\n",
    "    \"Paraphrase this: Ion think that plan gon' work.\",\n",
    "    max_retries=3\n",
    ")\n",
    "print(f\"Response with retry: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available models\n",
    "print(\"Available OpenAI models:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "models = openai_adapter.get_available_models()\n",
    "for model in models:\n",
    "    print(f\"‚Ä¢ {model}\")\n",
    "\n",
    "print(f\"\\nTotal models available: {len(models)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different Pro models\n",
    "print(\"Testing different OpenAI Pro models:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "models_to_test = [\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4-turbo\", \"o1-preview\"]\n",
    "test_prompt = \"Continue this sentence in the same style: We was tryna finish that yesterday\"\n",
    "\n",
    "for model in models_to_test:\n",
    "    try:\n",
    "        print(f\"\\nü§ñ Testing {model}:\")\n",
    "        adapter = OpenAIAdapter(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=300  # Higher limits with Pro\n",
    "        )\n",
    "        response = adapter.generate_response(test_prompt)\n",
    "        print(f\"Response: {response}\")\n",
    "        print(\"-\" * 40)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {model}: {e}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch processing with our stimuli data\n",
    "print(\"Loading stimuli data for batch processing:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "stimuli = pd.read_csv(\"../data/raw/stimuli.csv\")\n",
    "print(f\"Loaded {len(stimuli)} stimuli\")\n",
    "print(\"\\nFirst few examples:\")\n",
    "stimuli.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process examples with OpenAI Pro (higher rate limits)\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Processing stimuli with OpenAI Pro:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Reset to good settings for batch processing with Pro limits\n",
    "openai_adapter.update_config(temperature=0.5, max_tokens=500)\n",
    "\n",
    "responses = []\n",
    "for i, row in tqdm(stimuli.head(5).iterrows(), total=5):  # Process more with Pro\n",
    "    # Create task-specific prompt\n",
    "    if row.task == \"paraphrase\":\n",
    "        prompt = f\"Paraphrase this text in the same dialectal style: {row.text}\"\n",
    "    elif row.task == \"explain\":\n",
    "        prompt = f\"Explain this text in simple terms while preserving the dialectal style: {row.text}\"\n",
    "    elif row.task == \"continue\":\n",
    "        prompt = f\"Continue this text in the same dialectal style: {row.text}\"\n",
    "    else:\n",
    "        prompt = f\"Process this text while maintaining the dialectal style: {row.text}\"\n",
    "    \n",
    "    output = openai_adapter.generate_response(prompt)\n",
    "    responses.append({\n",
    "        \"id\": row.id,\n",
    "        \"variety\": row.variety,\n",
    "        \"task\": row.task,\n",
    "        \"input_text\": row.text,\n",
    "        \"output_text\": output\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "print(\"\\nOpenAI Pro responses:\")\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
