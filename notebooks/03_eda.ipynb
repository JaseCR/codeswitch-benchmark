{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85ff546",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Code-Switching in Language Models\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "This analysis addresses five key questions about how large language models handle dialectal and multilingual markers:\n",
    "\n",
    "1. **To what extent do large language models preserve dialectal or multilingual markers (AAVE, Spanglish, BrEng) when paraphrasing or continuing text?**\n",
    "   → This tests whether they code-switch naturally or standardize inputs.\n",
    "\n",
    "2. **Do certain models (Gemini, Cohere, Mistral) exhibit higher rates of dialect marker retention than others?**\n",
    "   → Compares stylistic sensitivity across model architectures.\n",
    "\n",
    "3. **How does output length differ across models and varieties?**\n",
    "   → Longer outputs may indicate over-explanation or normalization instead of faithful paraphrasing.\n",
    "\n",
    "4. **What is the relationship between token overlap and dialect preservation?**\n",
    "   → High overlap might mean literal paraphrasing; low overlap could reflect rewording or loss of style.\n",
    "\n",
    "5. **Are some language varieties more likely to be \"standardized\" than others?**\n",
    "   → For example, does Spanglish get translated to English more often than AAVE or British English?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d98e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa2963c",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8f4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stimuli data: 12 rows, 4 columns\n",
      "Loaded Gemini responses: 12 rows, 9 columns\n",
      "\n",
      "Dataset Overview:\n",
      "   Total examples: 12\n",
      "   Varieties: ['AAVE', 'Spanglish', 'BrEng', 'StdEng']\n",
      "   Tasks: ['paraphrase', 'explain', 'continue']\n",
      "   Gemini responses available: 12\n",
      "   Merged dataset: 12 rows\n"
     ]
    }
   ],
   "source": [
    "# Load stimuli data\n",
    "stimuli = pd.read_csv('../data/raw/stimuli.csv')\n",
    "print(f\"Loaded stimuli data: {stimuli.shape[0]} rows, {stimuli.shape[1]} columns\")\n",
    "\n",
    "# Load Gemini responses (the only model data we have)\n",
    "try:\n",
    "    gemini_data = pd.read_csv('../data/processed/gemini_scored.csv')\n",
    "    print(f\"Loaded Gemini responses: {gemini_data.shape[0]} rows, {gemini_data.shape[1]} columns\")\n",
    "    gemini_available = True\n",
    "except FileNotFoundError:\n",
    "    print(\"No Gemini response data found - will analyze stimuli only\")\n",
    "    gemini_available = False\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"   Total examples: {len(stimuli)}\")\n",
    "print(f\"   Varieties: {list(stimuli['variety'].unique())}\")\n",
    "print(f\"   Tasks: {list(stimuli['task'].unique())}\")\n",
    "\n",
    "if gemini_available:\n",
    "    print(f\"   Gemini responses available: {len(gemini_data)}\")\n",
    "    # Merge stimuli with Gemini responses for analysis\n",
    "    analysis_data = stimuli.merge(gemini_data, on='id', how='left')\n",
    "    print(f\"   Merged dataset: {len(analysis_data)} rows\")\n",
    "else:\n",
    "    print(\"   Model responses: Not available\")\n",
    "    analysis_data = stimuli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4320602",
   "metadata": {},
   "source": [
    "## Research Question 1: Dialectal Marker Preservation\n",
    "\n",
    "**Question:** To what extent do large language models preserve dialectal or multilingual markers when paraphrasing or continuing text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4a584c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'variety'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variety'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Simple visualization: Distribution of language varieties in our dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gemini_available:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Create a simple bar chart showing variety distribution\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     variety_counts \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariety\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      7\u001b[0m     bars \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mbar(variety_counts\u001b[38;5;241m.\u001b[39mindex, variety_counts\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[1;32m      8\u001b[0m                    color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#1f77b4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#ff7f0e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#2ca02c\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variety'"
     ]
    }
   ],
   "source": [
    "# Simple visualization: Distribution of language varieties in our dataset\n",
    "if gemini_available:\n",
    "    # Create a simple bar chart showing variety distribution\n",
    "    variety_counts = analysis_data['variety'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(variety_counts.index, variety_counts.values, \n",
    "                   color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    plt.title('Distribution of Language Varieties in Dataset', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Language Variety', fontsize=12)\n",
    "    plt.ylabel('Number of Examples', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show the actual counts\n",
    "    print(\"Language Variety Distribution:\")\n",
    "    for variety, count in variety_counts.items():\n",
    "        print(f\"  {variety}: {count} examples\")\n",
    "else:\n",
    "    # Fallback for stimuli-only analysis\n",
    "    variety_counts = stimuli['variety'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(variety_counts.index, variety_counts.values,\n",
    "                   color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    plt.title('Distribution of Language Varieties in Stimuli', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Language Variety', fontsize=12)\n",
    "    plt.ylabel('Number of Examples', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62f05e",
   "metadata": {},
   "source": [
    "**EDA Analysis:** This bar chart shows the distribution of different language varieties in our dataset. We have three main varieties: African American Vernacular English (AAVE), Spanglish (Spanish-English code-switching), and British English (BrEng). The balanced distribution allows us to compare how models handle different types of dialectal variation. This baseline helps us understand whether any observed differences in model performance are due to the models themselves or simply uneven data representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3429e8",
   "metadata": {},
   "source": [
    "## Research Question 2: Model Comparison for Dialect Retention\n",
    "\n",
    "**Question:** Do certain models (Gemini, Cohere, Mistral) exhibit higher rates of dialect marker retention than others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0944ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualization: Heatmap of code-switching detection by variety and task\n",
    "if gemini_available and 'has_code_switching' in analysis_data.columns:\n",
    "    # Create a pivot table for heatmap\n",
    "    pivot_data = analysis_data.pivot_table(\n",
    "        values='has_code_switching', \n",
    "        index='variety', \n",
    "        columns='task', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_data, annot=True, cmap='RdYlBu_r', \n",
    "                fmt='.2f', cbar_kws={'label': 'Code-Switching Detection Rate'})\n",
    "    plt.title('Code-Switching Detection Rate by Language Variety and Task\\n(Gemini Model)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Task Type', fontsize=12)\n",
    "    plt.ylabel('Language Variety', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"Code-Switching Detection Summary (Gemini):\")\n",
    "    print(f\"Overall detection rate: {analysis_data['has_code_switching'].mean():.2%}\")\n",
    "    print(\"\\nBy Variety:\")\n",
    "    variety_rates = analysis_data.groupby('variety')['has_code_switching'].mean()\n",
    "    for variety, rate in variety_rates.items():\n",
    "        print(f\"  {variety}: {rate:.2%}\")\n",
    "    print(\"\\nBy Task:\")\n",
    "    task_rates = analysis_data.groupby('task')['has_code_switching'].mean()\n",
    "    for task, rate in task_rates.items():\n",
    "        print(f\"  {task}: {rate:.2%}\")\n",
    "        \n",
    "else:\n",
    "    # Placeholder for when we have multiple model data\n",
    "    print(\"Note: Currently only Gemini data is available for model comparison.\")\n",
    "    print(\"This visualization will be expanded when Cohere and Mistral data are collected.\")\n",
    "    \n",
    "    # Show task distribution instead\n",
    "    task_counts = stimuli['task'].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pie(task_counts.values, labels=task_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribution of Task Types in Dataset', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0767941",
   "metadata": {},
   "source": [
    "**EDA Analysis:** The heatmap reveals patterns in how Gemini detects code-switching across different language varieties and tasks. Warmer colors (red) indicate higher detection rates, while cooler colors (blue) show lower rates. This visualization helps us identify whether certain language varieties are more likely to be recognized as code-switching, and whether different tasks (paraphrasing vs. continuation) affect detection accuracy. The summary statistics below provide quantitative measures to support the visual patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f5167",
   "metadata": {},
   "source": [
    "## Research Question 3: Output Length Analysis\n",
    "\n",
    "**Question:** How does output length differ across models and varieties?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2759a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualization: Box plot of response length by variety\n",
    "if gemini_available and 'response' in analysis_data.columns:\n",
    "    # Calculate response lengths\n",
    "    analysis_data['response_length'] = analysis_data['response'].str.len()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(data=analysis_data, x='variety', y='response_length', hue='task')\n",
    "    plt.title('Response Length Distribution by Language Variety and Task\\n(Gemini Model)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Language Variety', fontsize=12)\n",
    "    plt.ylabel('Response Length (characters)', fontsize=12)\n",
    "    plt.legend(title='Task Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical summary\n",
    "    print(\"Response Length Statistics (Gemini):\")\n",
    "    length_stats = analysis_data.groupby(['variety', 'task'])['response_length'].agg(['mean', 'std', 'count'])\n",
    "    print(length_stats.round(1))\n",
    "    \n",
    "    # Simple correlation analysis\n",
    "    print(f\"\\nCorrelation between variety and response length: {analysis_data['response_length'].corr(pd.Categorical(analysis_data['variety']).codes):.3f}\")\n",
    "    \n",
    "else:\n",
    "    # Show input length distribution instead\n",
    "    stimuli['input_length'] = stimuli['text'].str.len()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=stimuli, x='variety', y='input_length')\n",
    "    plt.title('Input Length Distribution by Language Variety', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Language Variety', fontsize=12)\n",
    "    plt.ylabel('Input Length (characters)', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Input Length Statistics:\")\n",
    "    print(stimuli.groupby('variety')['input_length'].describe().round(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e3a86",
   "metadata": {},
   "source": [
    "**EDA Analysis:** The box plots show the distribution of response lengths across different language varieties and tasks. The boxes represent the interquartile range (25th to 75th percentile), with the median shown as a line inside. Longer responses might indicate that models are over-explaining or normalizing dialectal features instead of maintaining the original style. If we see significant differences in length across varieties, this could suggest that certain dialects are being treated differently by the model, potentially losing their authentic characteristics in the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf7bfb",
   "metadata": {},
   "source": [
    "## Research Question 4: Token Overlap and Dialect Preservation\n",
    "\n",
    "**Question:** What is the relationship between token overlap and dialect preservation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualization: Scatter plot of token overlap vs code-switching detection\n",
    "if gemini_available and 'token_overlap' in analysis_data.columns and 'has_code_switching' in analysis_data.columns:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create scatter plot with different colors for each variety\n",
    "    varieties = analysis_data['variety'].unique()\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    for i, variety in enumerate(varieties):\n",
    "        variety_data = analysis_data[analysis_data['variety'] == variety]\n",
    "        plt.scatter(variety_data['token_overlap'], variety_data['has_code_switching'], \n",
    "                   c=colors[i], label=variety, alpha=0.6, s=50)\n",
    "    \n",
    "    plt.xlabel('Token Overlap (proportion)', fontsize=12)\n",
    "    plt.ylabel('Code-Switching Detected', fontsize=12)\n",
    "    plt.title('Relationship Between Token Overlap and Code-Switching Detection\\n(Gemini Model)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = analysis_data['token_overlap'].corr(analysis_data['has_code_switching'])\n",
    "    print(f\"Correlation between token overlap and code-switching detection: {correlation:.3f}\")\n",
    "    \n",
    "    # Summary by overlap ranges\n",
    "    analysis_data['overlap_range'] = pd.cut(analysis_data['token_overlap'], \n",
    "                                          bins=[0, 0.3, 0.6, 1.0], \n",
    "                                          labels=['Low (0-30%)', 'Medium (30-60%)', 'High (60-100%)'])\n",
    "    \n",
    "    overlap_summary = analysis_data.groupby('overlap_range')['has_code_switching'].mean()\n",
    "    print(\"\\nCode-switching detection rate by overlap range:\")\n",
    "    for range_name, rate in overlap_summary.items():\n",
    "        print(f\"  {range_name}: {rate:.2%}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Token overlap data not available for analysis.\")\n",
    "    print(\"This analysis will be available once token overlap calculations are implemented.\")\n",
    "    \n",
    "    # Show sample text lengths instead\n",
    "    if gemini_available and 'response' in analysis_data.columns:\n",
    "        # Simple word count analysis\n",
    "        analysis_data['input_words'] = analysis_data['text'].str.split().str.len()\n",
    "        analysis_data['response_words'] = analysis_data['response'].str.split().str.len()\n",
    "        analysis_data['word_ratio'] = analysis_data['response_words'] / analysis_data['input_words']\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=analysis_data, x='input_words', y='word_ratio', hue='variety')\n",
    "        plt.xlabel('Input Word Count', fontsize=12)\n",
    "        plt.ylabel('Response/Input Word Ratio', fontsize=12)\n",
    "        plt.title('Response Expansion by Input Length and Variety\\n(Gemini Model)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Word count expansion by variety:\")\n",
    "        print(analysis_data.groupby('variety')['word_ratio'].mean().round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc7bb1",
   "metadata": {},
   "source": [
    "**EDA Analysis:** This scatter plot examines the relationship between token overlap (how much the response shares words with the input) and code-switching detection. High overlap might indicate literal paraphrasing that preserves dialectal features, while low overlap could suggest more creative rewording that might lose stylistic elements. The correlation coefficient tells us the strength and direction of this relationship. If we see different patterns for different language varieties, it suggests that models treat dialects differently when generating responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4adc0",
   "metadata": {},
   "source": [
    "## Research Question 5: Language Variety Standardization\n",
    "\n",
    "**Question:** Are some language varieties more likely to be \"standardized\" than others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff61dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualization: Multi-panel analysis of standardization patterns\n",
    "if gemini_available and 'has_code_switching' in analysis_data.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Code-switching detection rate by variety\n",
    "    variety_rates = analysis_data.groupby('variety')['has_code_switching'].mean()\n",
    "    axes[0, 0].bar(variety_rates.index, variety_rates.values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    axes[0, 0].set_title('Code-Switching Detection Rate by Variety', fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Detection Rate')\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    for i, v in enumerate(variety_rates.values):\n",
    "        axes[0, 0].text(i, v + 0.02, f'{v:.2%}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # 2. Response length variation by variety\n",
    "    length_by_variety = analysis_data.groupby('variety')['response_length']\n",
    "    axes[0, 1].boxplot([length_by_variety.get_group(v) for v in variety_rates.index], \n",
    "                       labels=variety_rates.index)\n",
    "    axes[0, 1].set_title('Response Length Distribution by Variety', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Response Length (characters)')\n",
    "    \n",
    "    # 3. Task-specific patterns\n",
    "    task_variety_pivot = analysis_data.pivot_table(\n",
    "        values='has_code_switching', index='variety', columns='task', aggfunc='mean'\n",
    "    )\n",
    "    im = axes[1, 0].imshow(task_variety_pivot.values, cmap='RdYlBu_r', aspect='auto')\n",
    "    axes[1, 0].set_title('Code-Switching Detection by Variety and Task', fontweight='bold')\n",
    "    axes[1, 0].set_xticks(range(len(task_variety_pivot.columns)))\n",
    "    axes[1, 0].set_xticklabels(task_variety_pivot.columns)\n",
    "    axes[1, 0].set_yticks(range(len(task_variety_pivot.index)))\n",
    "    axes[1, 0].set_yticklabels(task_variety_pivot.index)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(task_variety_pivot.index)):\n",
    "        for j in range(len(task_variety_pivot.columns)):\n",
    "            axes[1, 0].text(j, i, f'{task_variety_pivot.iloc[i, j]:.2f}', \n",
    "                           ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # 4. Summary statistics\n",
    "    axes[1, 1].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    Standardization Analysis Summary:\n",
    "    \n",
    "    Overall Detection Rate: {analysis_data['has_code_switching'].mean():.1%}\n",
    "    \n",
    "    By Variety:\n",
    "    • AAVE: {variety_rates.get('AAVE', 0):.1%}\n",
    "    • Spanglish: {variety_rates.get('Spanglish', 0):.1%}\n",
    "    • BrEng: {variety_rates.get('BrEng', 0):.1%}\n",
    "    \n",
    "    Interpretation:\n",
    "    Lower detection rates may indicate\n",
    "    that models are standardizing\n",
    "    dialectal features rather than\n",
    "    preserving them.\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.9, summary_text, transform=axes[1, 1].transAxes, \n",
    "                    fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical test for differences\n",
    "    from scipy.stats import chi2_contingency\n",
    "    contingency_table = pd.crosstab(analysis_data['variety'], analysis_data['has_code_switching'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f\"Chi-square test for variety differences: χ² = {chi2:.3f}, p = {p_value:.3f}\")\n",
    "    \n",
    "else:\n",
    "    # Simplified analysis for stimuli only\n",
    "    print(\"Model response data not available for standardization analysis.\")\n",
    "    print(\"This analysis requires model outputs to assess standardization patterns.\")\n",
    "    \n",
    "    # Show variety characteristics instead\n",
    "    variety_chars = stimuli.groupby('variety').agg({\n",
    "        'text': ['count', lambda x: x.str.len().mean()]\n",
    "    }).round(1)\n",
    "    variety_chars.columns = ['Count', 'Avg_Length']\n",
    "    print(\"\\nVariety Characteristics in Stimuli:\")\n",
    "    print(variety_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7940db8",
   "metadata": {},
   "source": [
    "**EDA Analysis:** This comprehensive multi-panel visualization examines standardization patterns across language varieties. The top-left panel shows detection rates, where lower rates suggest more standardization. The top-right panel reveals response length patterns that might indicate over-explanation for certain varieties. The bottom-left heatmap shows task-specific effects, and the bottom-right panel provides a statistical summary. The chi-square test determines whether differences between varieties are statistically significant. This analysis helps identify which language varieties are most likely to be \"standardized\" or normalized by language models, potentially losing their authentic dialectal characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d9a97",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This exploratory data analysis has examined five key research questions about code-switching in language models. The visualizations and statistical analyses provide insights into how different models handle dialectal and multilingual markers across various language varieties.\n",
    "\n",
    "**Key Findings:**\n",
    "- The analysis reveals patterns in dialect preservation across different language varieties\n",
    "- Model responses show varying degrees of standardization depending on the input variety\n",
    "- Response length and token overlap patterns suggest different approaches to handling dialectal features\n",
    "- Statistical tests help determine whether observed differences are significant\n",
    "\n",
    "**Next Steps:**\n",
    "- Collect data from Cohere and Mistral models for comprehensive model comparison\n",
    "- Implement token overlap calculations for more detailed linguistic analysis\n",
    "- Expand the dataset with additional language varieties and tasks\n",
    "- Develop quantitative metrics for measuring dialect preservation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14308e71",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Code-Switching in Language Models\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "This analysis addresses five key questions about how large language models handle dialectal and multilingual markers:\n",
    "\n",
    "1. **To what extent do large language models preserve dialectal or multilingual markers (AAVE, Spanglish, BrEng) when paraphrasing or continuing text?**\n",
    "   → This tests whether they code-switch naturally or standardize inputs.\n",
    "\n",
    "2. **Do certain models (e.g., GPT-4, Claude, Gemini, Cohere) exhibit higher rates of dialect marker retention than others?**\n",
    "   → Compares stylistic sensitivity across model architectures.\n",
    "\n",
    "3. **How does output length differ across models and varieties?**\n",
    "   → Longer outputs may indicate over-explanation or normalization instead of faithful paraphrasing.\n",
    "\n",
    "4. **What is the relationship between token overlap and dialect preservation?**\n",
    "   → High overlap might mean literal paraphrasing; low overlap could reflect rewording or loss of style.\n",
    "\n",
    "5. **Are some language varieties more likely to be \"standardized\" than others?**\n",
    "   → For example, does Spanglish get translated to English more often than AAVE or British English?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855ac2b",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a37259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stimuli data\n",
    "stimuli = pd.read_csv('../data/raw/stimuli.csv')\n",
    "print(f\"Loaded stimuli data: {stimuli.shape[0]} rows, {stimuli.shape[1]} columns\")\n",
    "\n",
    "# Load Gemini responses (the only model data we have)\n",
    "try:\n",
    "    gemini_data = pd.read_csv('../data/processed/gemini_scored.csv')\n",
    "    print(f\"Loaded Gemini responses: {gemini_data.shape[0]} rows, {gemini_data.shape[1]} columns\")\n",
    "    gemini_available = True\n",
    "except FileNotFoundError:\n",
    "    print(\"No Gemini response data found - will analyze stimuli only\")\n",
    "    gemini_available = False\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"   Total examples: {len(stimuli)}\")\n",
    "print(f\"   Varieties: {list(stimuli['variety'].unique())}\")\n",
    "print(f\"   Tasks: {list(stimuli['task'].unique())}\")\n",
    "\n",
    "if gemini_available:\n",
    "    print(f\"   Gemini responses available: {len(gemini_data)}\")\n",
    "else:\n",
    "    print(\"   Model responses: Not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa399a5b",
   "metadata": {},
   "source": [
    "## Research Question 1: Dialectal Marker Preservation\n",
    "\n",
    "**Question:** To what extent do large language models preserve dialectal or multilingual markers when paraphrasing or continuing text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a02f1d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f29e1a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Code-Switching in Language Models\n",
    "\n",
    "## Research Question\n",
    "**Do GPT models maintain code-switching patterns when paraphrasing or continuing text in different linguistic varieties?**\n",
    "\n",
    "This analysis examines how various language models (OpenAI, Gemini, Cohere, Mistral) handle code-switching tasks across four linguistic varieties:\n",
    "- **AAVE** (African American Vernacular English)\n",
    "- **Spanglish** (Spanish-English code-switching)\n",
    "- **BrEng** (British English)\n",
    "- **StdEng** (Standard English)\n",
    "\n",
    "## Analysis Overview\n",
    "We will evaluate whether language models preserve dialectal markers and code-switching patterns when processing text, which is crucial for understanding their cultural and linguistic sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a24686",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview\n",
    "\n",
    "We begin by loading the stimuli dataset to understand the structure of our code-switching benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0003a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stimuli data\n",
    "stimuli = pd.read_csv('../data/raw/stimuli.csv')\n",
    "print(f\"Loaded stimuli data: {stimuli.shape[0]} rows, {stimuli.shape[1]} columns\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"   Total examples: {len(stimuli)}\")\n",
    "print(f\"   Varieties: {list(stimuli['variety'].unique())}\")\n",
    "print(f\"   Tasks: {list(stimuli['task'].unique())}\")\n",
    "\n",
    "# Show first few examples\n",
    "print(\"\\nFirst 5 examples:\")\n",
    "stimuli.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d0b83",
   "metadata": {},
   "source": [
    "## 2. Dataset Distribution Analysis\n",
    "\n",
    "Understanding the distribution of linguistic varieties and tasks is crucial for evaluating whether our benchmark adequately represents different code-switching scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variety distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Variety distribution pie chart\n",
    "variety_counts = stimuli['variety'].value_counts()\n",
    "ax1.pie(variety_counts.values, labels=variety_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Distribution of Linguistic Varieties')\n",
    "\n",
    "# Task distribution bar chart\n",
    "task_counts = stimuli['task'].value_counts()\n",
    "task_counts.plot(kind='bar', ax=ax2, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax2.set_title('Distribution of Task Types')\n",
    "ax2.set_xlabel('Task Type')\n",
    "ax2.set_ylabel('Number of Examples')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Variety Distribution:\")\n",
    "for variety, count in variety_counts.items():\n",
    "    print(f\"  {variety}: {count} examples\")\n",
    "\n",
    "print(\"\\nTask Distribution:\")\n",
    "for task, count in task_counts.items():\n",
    "    print(f\"  {task}: {count} examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1112c2",
   "metadata": {},
   "source": [
    "**Interpretation:** This balanced distribution across linguistic varieties (25% each) ensures that our analysis covers diverse code-switching patterns. The equal representation of AAVE, Spanglish, British English, and Standard English allows us to compare how language models handle different types of linguistic variation. The task distribution shows that we have equal representation of paraphrase, explain, and continue tasks, which helps us understand whether models maintain code-switching across different types of text transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd7c34",
   "metadata": {},
   "source": [
    "## 3. Text Length and Complexity Analysis\n",
    "\n",
    "Analyzing the length and complexity of our stimuli helps us understand whether the benchmark presents appropriate challenges for language models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text statistics\n",
    "stimuli['text_length'] = stimuli['text'].str.len()\n",
    "stimuli['word_count'] = stimuli['text'].str.split().str.len()\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Text length by variety\n",
    "stimuli.boxplot(column='text_length', by='variety', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Text Length by Linguistic Variety')\n",
    "axes[0, 0].set_xlabel('Variety')\n",
    "axes[0, 0].set_ylabel('Character Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Word count by variety\n",
    "stimuli.boxplot(column='word_count', by='variety', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Word Count by Linguistic Variety')\n",
    "axes[0, 1].set_xlabel('Variety')\n",
    "axes[0, 1].set_ylabel('Word Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Text length distribution\n",
    "axes[1, 0].hist(stimuli['text_length'], bins=10, alpha=0.7, color='#FF6B6B')\n",
    "axes[1, 0].set_title('Overall Text Length Distribution')\n",
    "axes[1, 0].set_xlabel('Character Count')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Word count distribution\n",
    "axes[1, 1].hist(stimuli['word_count'], bins=10, alpha=0.7, color='#4ECDC4')\n",
    "axes[1, 1].set_title('Overall Word Count Distribution')\n",
    "axes[1, 1].set_xlabel('Word Count')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Text Statistics Summary:\")\n",
    "print(f\"  Average text length: {stimuli['text_length'].mean():.1f} characters\")\n",
    "print(f\"  Average word count: {stimuli['word_count'].mean():.1f} words\")\n",
    "print(f\"  Text length range: {stimuli['text_length'].min()} - {stimuli['text_length'].max()} characters\")\n",
    "print(f\"  Word count range: {stimuli['word_count'].min()} - {stimuli['word_count'].max()} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd215b9",
   "metadata": {},
   "source": [
    "**Interpretation:** The text length and word count distributions show that our stimuli are relatively short and consistent in length, which is appropriate for code-switching analysis. Short texts allow us to focus on specific dialectal markers without the complexity of longer passages. The boxplots by variety reveal whether certain linguistic varieties tend to have longer or shorter expressions, which could influence how language models process them. Consistent length across varieties ensures fair comparison of model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f25d3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e9fea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4b9c84f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1ee1f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405181a1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Code-Switching in Language Models\n",
    "\n",
    "## Research Question\n",
    "**Do GPT models maintain code-switching patterns when paraphrasing or continuing text in different linguistic varieties?**\n",
    "\n",
    "This analysis examines how various language models (OpenAI, Gemini, Cohere, Mistral) handle code-switching tasks across four linguistic varieties:\n",
    "- **AAVE** (African American Vernacular English)\n",
    "- **Spanglish** (Spanish-English code-switching)\n",
    "- **BrEng** (British English)\n",
    "- **StdEng** (Standard English)\n",
    "\n",
    "## Analysis Overview\n",
    "We will evaluate whether language models preserve dialectal markers and code-switching patterns when processing text, which is crucial for understanding their cultural and linguistic sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Add src to path for API imports\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    src_path = os.path.join('..', 'src')\n",
    "else:\n",
    "    src_path = 'src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Working directory: {current_dir}\")\n",
    "print(f\"Python path includes: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e62f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load original stimuli data\n",
    "try:\n",
    "    stimuli = pd.read_csv('../data/raw/stimuli.csv')\n",
    "    print(f\"Loaded stimuli data: {stimuli.shape[0]} rows, {stimuli.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(\"stimuli.csv not found. Creating sample data...\")\n",
    "    stimuli = pd.DataFrame({\n",
    "        'id': range(1, 101),\n",
    "        'variety': np.random.choice(['AAVE', 'Spanglish', 'British English', 'Indian English'], 100),\n",
    "        'task': np.random.choice(['paraphrase', 'continue', 'translate'], 100),\n",
    "        'text': [f\"Sample text {i} with some code-switching content.\" for i in range(1, 101)]\n",
    "    })\n",
    "\n",
    "# Load API response data\n",
    "api_responses = {}\n",
    "apis = ['openai', 'anthropic', 'gemini', 'cohere']\n",
    "\n",
    "for api in apis:\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/raw/{api}_responses.csv')\n",
    "        api_responses[api] = df\n",
    "        print(f\"✅ Loaded {api} responses: {df.shape[0]} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  {api}_responses.csv not found - will create during analysis\")\n",
    "\n",
    "print(f\"\\n📊 Available datasets:\")\n",
    "print(f\"- Stimuli: {stimuli.shape[0]} rows\")\n",
    "for api, df in api_responses.items():\n",
    "    print(f\"- {api.title()} responses: {df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Assessment\n",
    "print(\"🔍 Data Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(stimuli.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {stimuli.isnull().sum().sum()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {stimuli.duplicated().sum()}\")\n",
    "\n",
    "# Basic statistics for text length\n",
    "stimuli['text_length'] = stimuli['text'].str.len()\n",
    "stimuli['word_count'] = stimuli['text'].str.split().str.len()\n",
    "\n",
    "print(f\"\\n📏 Text Statistics:\")\n",
    "print(f\"Average text length: {stimuli['text_length'].mean():.1f} characters\")\n",
    "print(f\"Average word count: {stimuli['word_count'].mean():.1f} words\")\n",
    "print(f\"Text length range: {stimuli['text_length'].min()} - {stimuli['text_length'].max()} characters\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\n📊 Summary Statistics:\")\n",
    "stimuli[['text_length', 'word_count']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223a866",
   "metadata": {},
   "source": [
    "## 1. Stimuli Data Analysis\n",
    "\n",
    "Let's examine the original stimuli data, including data quality, distributions, and basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Assessment\n",
    "print(\"🔍 Stimuli Data Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(stimuli.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {stimuli.isnull().sum().sum()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {stimuli.duplicated().sum()}\")\n",
    "\n",
    "# Basic statistics for text length\n",
    "stimuli['text_length'] = stimuli['text'].str.len()\n",
    "stimuli['word_count'] = stimuli['text'].str.split().str.len()\n",
    "\n",
    "print(f\"\\n📏 Text Statistics:\")\n",
    "print(f\"Average text length: {stimuli['text_length'].mean():.1f} characters\")\n",
    "print(f\"Average word count: {stimuli['word_count'].mean():.1f} words\")\n",
    "print(f\"Text length range: {stimuli['text_length'].min()} - {stimuli['text_length'].max()} characters\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\n📊 Summary Statistics:\")\n",
    "stimuli[['text_length', 'word_count']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Analysis\n",
    "print(\"📊 Distribution Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create subplots for distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Stimuli Data Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Variety distribution\n",
    "variety_counts = stimuli['variety'].value_counts()\n",
    "axes[0, 0].pie(variety_counts.values, labels=variety_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Distribution by Linguistic Variety')\n",
    "\n",
    "# 2. Task distribution\n",
    "task_counts = stimuli['task'].value_counts()\n",
    "axes[0, 1].bar(task_counts.index, task_counts.values, color=sns.color_palette(\"husl\", len(task_counts)))\n",
    "axes[0, 1].set_title('Distribution by Task Type')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Text length distribution\n",
    "axes[1, 0].hist(stimuli['text_length'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1, 0].set_title('Text Length Distribution')\n",
    "axes[1, 0].set_xlabel('Character Count')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 4. Word count distribution\n",
    "axes[1, 1].hist(stimuli['word_count'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 1].set_title('Word Count Distribution')\n",
    "axes[1, 1].set_xlabel('Word Count')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display counts\n",
    "print(\"📈 Variety Distribution:\")\n",
    "print(variety_counts)\n",
    "print(f\"\\n📈 Task Distribution:\")\n",
    "print(task_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a4af2",
   "metadata": {},
   "source": [
    "## 2. API Response Analysis\n",
    "\n",
    "Now let's analyze the responses from different APIs and compare their performance across linguistic varieties and tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Response Analysis Function\n",
    "def analyze_api_responses(api_name, df):\n",
    "    \"\"\"\n",
    "    Analyze API responses and return key metrics\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Calculate response metrics\n",
    "    df['response_length'] = df['output_text'].str.len()\n",
    "    df['response_words'] = df['output_text'].str.split().str.len()\n",
    "    \n",
    "    # Check for errors\n",
    "    error_count = df['output_text'].str.contains('ERROR:', na=False).sum()\n",
    "    \n",
    "    return {\n",
    "        'api': api_name,\n",
    "        'total_responses': len(df),\n",
    "        'error_count': error_count,\n",
    "        'success_rate': (len(df) - error_count) / len(df) * 100,\n",
    "        'avg_response_length': df['response_length'].mean(),\n",
    "        'avg_response_words': df['response_words'].mean(),\n",
    "        'variety_distribution': df['variety'].value_counts().to_dict(),\n",
    "        'task_distribution': df['task'].value_counts().to_dict()\n",
    "    }\n",
    "\n",
    "# Analyze all available API responses\n",
    "print(\"🔍 API Response Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "api_metrics = {}\n",
    "for api_name, df in api_responses.items():\n",
    "    metrics = analyze_api_responses(api_name, df)\n",
    "    if metrics:\n",
    "        api_metrics[api_name] = metrics\n",
    "        print(f\"\\n📊 {api_name.upper()} Analysis:\")\n",
    "        print(f\"  Total responses: {metrics['total_responses']}\")\n",
    "        print(f\"  Success rate: {metrics['success_rate']:.1f}%\")\n",
    "        print(f\"  Avg response length: {metrics['avg_response_length']:.1f} characters\")\n",
    "        print(f\"  Avg response words: {metrics['avg_response_words']:.1f} words\")\n",
    "\n",
    "if not api_metrics:\n",
    "    print(\"⚠️  No API response data available yet. Run data collection notebooks first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Comparison Visualization\n",
    "if api_metrics:\n",
    "    print(\"\\n📈 Creating Performance Comparison Visualizations...\")\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_data = []\n",
    "    for api, metrics in api_metrics.items():\n",
    "        comparison_data.append({\n",
    "            'API': api.title(),\n",
    "            'Success Rate (%)': metrics['success_rate'],\n",
    "            'Avg Response Length': metrics['avg_response_length'],\n",
    "            'Avg Response Words': metrics['avg_response_words'],\n",
    "            'Total Responses': metrics['total_responses']\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Create subplots for comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('API Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Success Rate Comparison\n",
    "    axes[0, 0].bar(comparison_df['API'], comparison_df['Success Rate (%)'], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[0, 0].set_title('Success Rate by API')\n",
    "    axes[0, 0].set_ylabel('Success Rate (%)')\n",
    "    axes[0, 0].set_ylim(0, 100)\n",
    "    \n",
    "    # 2. Response Length Comparison\n",
    "    axes[0, 1].bar(comparison_df['API'], comparison_df['Avg Response Length'], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[0, 1].set_title('Average Response Length')\n",
    "    axes[0, 1].set_ylabel('Characters')\n",
    "    \n",
    "    # 3. Response Word Count\n",
    "    axes[1, 0].bar(comparison_df['API'], comparison_df['Avg Response Words'], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[1, 0].set_title('Average Response Word Count')\n",
    "    axes[1, 0].set_ylabel('Words')\n",
    "    \n",
    "    # 4. Total Responses\n",
    "    axes[1, 1].bar(comparison_df['API'], comparison_df['Total Responses'], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[1, 1].set_title('Total Responses Collected')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\n📊 API Performance Summary:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"⚠️  No API data available for comparison. Run data collection first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb989775",
   "metadata": {},
   "source": [
    "## 3. Linguistic Analysis & Code-Switching Patterns\n",
    "\n",
    "Let's dive deeper into the linguistic patterns and code-switching behavior across different varieties and tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e14f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linguistic Analysis Functions\n",
    "def extract_linguistic_features(text):\n",
    "    \"\"\"\n",
    "    Extract linguistic features from text for analysis\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {}\n",
    "    \n",
    "    # Basic features\n",
    "    features = {\n",
    "        'length': len(text),\n",
    "        'words': len(text.split()),\n",
    "        'sentences': len(text.split('.')),\n",
    "        'uppercase_ratio': sum(1 for c in text if c.isupper()) / len(text) if text else 0,\n",
    "        'digit_ratio': sum(1 for c in text if c.isdigit()) / len(text) if text else 0,\n",
    "        'punctuation_ratio': sum(1 for c in text if c in '.,!?;:') / len(text) if text else 0\n",
    "    }\n",
    "    \n",
    "    # Language-specific patterns (basic detection)\n",
    "    features['has_spanish'] = any(word in text.lower() for word in ['el', 'la', 'de', 'que', 'en', 'un', 'una', 'con', 'por', 'para'])\n",
    "    features['has_french'] = any(word in text.lower() for word in ['le', 'la', 'de', 'et', 'du', 'des', 'que', 'dans', 'sur'])\n",
    "    features['has_arabic_patterns'] = any(char in text for char in 'ا ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ك ل م ن ه و ي ء')\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Analyze linguistic features across varieties\n",
    "print(\"🔍 Linguistic Feature Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Apply linguistic analysis to stimuli\n",
    "linguistic_features = []\n",
    "for idx, row in stimuli.iterrows():\n",
    "    features = extract_linguistic_features(row['text'])\n",
    "    features.update({\n",
    "        'id': row['id'],\n",
    "        'variety': row['variety'],\n",
    "        'task': row['task']\n",
    "    })\n",
    "    linguistic_features.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(linguistic_features)\n",
    "\n",
    "# Display summary statistics by variety\n",
    "print(\"📊 Linguistic Features by Variety:\")\n",
    "variety_stats = features_df.groupby('variety').agg({\n",
    "    'words': ['mean', 'std'],\n",
    "    'uppercase_ratio': ['mean', 'std'],\n",
    "    'punctuation_ratio': ['mean', 'std'],\n",
    "    'has_spanish': 'sum',\n",
    "    'has_french': 'sum',\n",
    "    'has_arabic_patterns': 'sum'\n",
    "}).round(3)\n",
    "\n",
    "print(variety_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word Clouds for each variety\n",
    "print(\"\\n☁️ Generating Word Clouds by Variety...\")\n",
    "\n",
    "# Prepare text data for word clouds\n",
    "variety_texts = {}\n",
    "for variety in stimuli['variety'].unique():\n",
    "    variety_texts[variety] = ' '.join(stimuli[stimuli['variety'] == variety]['text'].astype(str))\n",
    "\n",
    "# Create word cloud visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Word Clouds by Linguistic Variety', fontsize=20, fontweight='bold')\n",
    "\n",
    "varieties = list(variety_texts.keys())\n",
    "for i, variety in enumerate(varieties):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    if variety in variety_texts and variety_texts[variety].strip():\n",
    "        # Generate word cloud\n",
    "        wordcloud = WordCloud(\n",
    "            width=800, height=400, \n",
    "            background_color='white',\n",
    "            colormap='viridis',\n",
    "            max_words=100,\n",
    "            relative_scaling=0.5\n",
    "        ).generate(variety_texts[variety])\n",
    "        \n",
    "        axes[row, col].imshow(wordcloud, interpolation='bilinear')\n",
    "        axes[row, col].set_title(f'{variety} Word Cloud', fontsize=14, fontweight='bold')\n",
    "        axes[row, col].axis('off')\n",
    "    else:\n",
    "        axes[row, col].text(0.5, 0.5, f'No text data for {variety}', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "        axes[row, col].set_title(f'{variety} (No Data)', fontsize=14)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Word clouds generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2df19",
   "metadata": {},
   "source": [
    "## 4. Advanced Visualizations & Creative Analysis\n",
    "\n",
    "Now let's create some really creative and insightful visualizations that go beyond basic charts. We'll explore patterns, relationships, and unique insights across the different APIs and linguistic varieties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2beedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Performance Heatmap\n",
    "if api_metrics:\n",
    "    # Create performance data\n",
    "    performance_data = []\n",
    "    for api, metrics in api_metrics.items():\n",
    "        performance_data.append({\n",
    "            'API': api.title(),\n",
    "            'Success Rate': metrics['success_rate'],\n",
    "            'Avg Response Length': metrics['avg_response_length'],\n",
    "            'Avg Response Words': metrics['avg_response_words'],\n",
    "            'Total Responses': metrics['total_responses']\n",
    "        })\n",
    "    \n",
    "    perf_df = pd.DataFrame(performance_data)\n",
    "    \n",
    "    # Normalize data for heatmap\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    numeric_cols = ['Success Rate', 'Avg Response Length', 'Avg Response Words', 'Total Responses']\n",
    "    heatmap_data = perf_df[numeric_cols].copy()\n",
    "    \n",
    "    # Scale to 0-1\n",
    "    heatmap_data_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(heatmap_data),\n",
    "        columns=numeric_cols,\n",
    "        index=perf_df['API']\n",
    "    )\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        heatmap_data_scaled.T, \n",
    "        annot=True, \n",
    "        cmap='RdYlBu_r',\n",
    "        cbar_kws={'label': 'Performance Score'},\n",
    "        fmt='.2f'\n",
    "    )\n",
    "    \n",
    "    plt.title('API Performance Heatmap', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('APIs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No API data available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Bubble Chart\n",
    "if api_metrics:\n",
    "    # Prepare data\n",
    "    bubble_data = []\n",
    "    for api, metrics in api_metrics.items():\n",
    "        bubble_data.append({\n",
    "            'API': api.title(),\n",
    "            'Success Rate': metrics['success_rate'],\n",
    "            'Avg Response Length': metrics['avg_response_length'],\n",
    "            'Total Responses': metrics['total_responses'],\n",
    "            'Avg Response Words': metrics['avg_response_words']\n",
    "        })\n",
    "    \n",
    "    bubble_df = pd.DataFrame(bubble_data)\n",
    "    \n",
    "    # Create bubble chart\n",
    "    fig = px.scatter(\n",
    "        bubble_df, \n",
    "        x='Success Rate', \n",
    "        y='Avg Response Length',\n",
    "        size='Total Responses',\n",
    "        color='Avg Response Words',\n",
    "        hover_name='API',\n",
    "        title='API Performance Bubble Chart',\n",
    "        color_continuous_scale='Viridis',\n",
    "        size_max=50\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(width=900, height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No API data available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc6c09",
   "metadata": {},
   "source": [
    "# FIXED - Gemini Analysis using correct data source\n",
    "try:\n",
    "    # Load Gemini data from the correct file\n",
    "    gemini_data = pd.read_csv('../data/processed/gemini_scored.csv')\n",
    "    print(f\"✅ Loaded {len(gemini_data)} Gemini responses\")\n",
    "    \n",
    "    # Calculate response metrics\n",
    "    gemini_data['response_quality_score'] = (\n",
    "        gemini_data['output_text'].str.len() / gemini_data['input_text'].str.len()\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Detect code-switching patterns\n",
    "    gemini_data['has_code_switching'] = gemini_data['output_text'].str.contains(\n",
    "        r'\\b(el|la|de|que|en|un|una|con|por|para|finna|bout|real)\\b', \n",
    "        case=False, na=False\n",
    "    )\n",
    "    \n",
    "    # Create analysis visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Gemini Response Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Quality distribution\n",
    "    axes[0, 0].hist(gemini_data['response_quality_score'], bins=20, alpha=0.7, color='#4285F4')\n",
    "    axes[0, 0].set_title('Response Quality Distribution')\n",
    "    axes[0, 0].set_xlabel('Quality Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 2. Length distribution\n",
    "    axes[0, 1].hist(gemini_data['output_text'].str.len(), bins=30, alpha=0.7, color='#34A853')\n",
    "    axes[0, 1].set_title('Response Length Distribution')\n",
    "    axes[0, 1].set_xlabel('Characters')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # 3. Code-switching detection\n",
    "    cs_counts = gemini_data['has_code_switching'].value_counts()\n",
    "    \n",
    "    # Use bar chart to avoid label issues\n",
    "    if len(cs_counts) > 0:\n",
    "        labels = []\n",
    "        values = []\n",
    "        colors = []\n",
    "        \n",
    "        if False in cs_counts.index:\n",
    "            labels.append('No Code-Switching')\n",
    "            values.append(cs_counts[False])\n",
    "            colors.append('#EA4335')\n",
    "        if True in cs_counts.index:\n",
    "            labels.append('Has Code-Switching')\n",
    "            values.append(cs_counts[True])\n",
    "            colors.append('#FBBC04')\n",
    "            \n",
    "        axes[1, 0].bar(labels, values, color=colors)\n",
    "        axes[1, 0].set_title('Code-Switching Detection')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = sum(values)\n",
    "        for i, v in enumerate(values):\n",
    "            axes[1, 0].text(i, v + 0.1, f'{v/total:.1%}', ha='center', va='bottom')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No Data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Code-Switching Detection')\n",
    "    \n",
    "    # 4. Quality vs Length correlation\n",
    "    axes[1, 1].scatter(gemini_data['output_text'].str.len(), \n",
    "                       gemini_data['response_quality_score'],\n",
    "                       alpha=0.6, color='#4285F4')\n",
    "    axes[1, 1].set_title('Length vs Quality')\n",
    "    axes[1, 1].set_xlabel('Response Length')\n",
    "    axes[1, 1].set_ylabel('Quality Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\nGemini Performance Summary:\")\n",
    "    print(f\"  Average Quality Score: {gemini_data['response_quality_score'].mean():.3f}\")\n",
    "    print(f\"  Code-Switching Rate: {gemini_data['has_code_switching'].mean():.1%}\")\n",
    "    print(f\"  Average Response Length: {gemini_data['output_text'].str.len().mean():.0f} characters\")\n",
    "    print(f\"  Total Responses: {len(gemini_data)}\")\n",
    "    print(f\"  Varieties: {gemini_data['variety'].unique()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Gemini data file not found: ../data/processed/gemini_scored.csv\")\n",
    "    print(\"💡 Make sure you've run the data collection notebook first\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading Gemini data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff403400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c683fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98833e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa7316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4133dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3321c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab614730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative Visualization 3: Radar Chart for API Capabilities\n",
    "print(\"🎨 Creating Radar Chart for API Capabilities...\")\n",
    "\n",
    "if api_metrics:\n",
    "    # Prepare data for radar chart\n",
    "    radar_data = {}\n",
    "    for api, metrics in api_metrics.items():\n",
    "        radar_data[api.title()] = [\n",
    "            metrics['success_rate'],\n",
    "            min(metrics['avg_response_length'] / 100, 100),  # Normalize length\n",
    "            min(metrics['avg_response_words'] * 2, 100),     # Normalize words\n",
    "            min(metrics['total_responses'] * 2, 100)         # Normalize total\n",
    "        ]\n",
    "    \n",
    "    # Define categories\n",
    "    categories = ['Success Rate', 'Response Length', 'Word Count', 'Volume']\n",
    "    \n",
    "    # Create radar chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n",
    "    \n",
    "    for i, (api, values) in enumerate(radar_data.items()):\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values + [values[0]],  # Close the radar chart\n",
    "            theta=categories + [categories[0]],\n",
    "            fill='toself',\n",
    "            name=api,\n",
    "            line_color=colors[i % len(colors)],\n",
    "            fillcolor=colors[i % len(colors)],\n",
    "            opacity=0.3\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                visible=True,\n",
    "                range=[0, 100]\n",
    "            )),\n",
    "        showlegend=True,\n",
    "        title=\"🎯 API Capabilities Radar Chart\",\n",
    "        font_size=12,\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(\"✅ Radar chart created!\")\n",
    "else:\n",
    "    print(\"⚠️  No API data available for radar chart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82581fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative Visualization 4: Sankey Diagram for API Flow Analysis\n",
    "print(\"🎨 Creating Sankey Diagram for API Flow...\")\n",
    "\n",
    "if api_metrics:\n",
    "    # Create Sankey diagram showing data flow through APIs\n",
    "    labels = []\n",
    "    sources = []\n",
    "    targets = []\n",
    "    values = []\n",
    "    \n",
    "    # Define nodes\n",
    "    node_labels = ['Input Stimuli', 'OpenAI', 'Gemini', 'Cohere', 'Mistral', 'Successful Output', 'Failed Output']\n",
    "    node_indices = {label: i for i, label in enumerate(node_labels)}\n",
    "    \n",
    "    # Add flows from input to each API\n",
    "    for api, metrics in api_metrics.items():\n",
    "        api_name = api.title()\n",
    "        if api_name in ['Openai', 'Gemini', 'Cohere', 'Mistral']:\n",
    "            # Flow from input to API\n",
    "            sources.append(node_indices['Input Stimuli'])\n",
    "            targets.append(node_indices[api_name])\n",
    "            values.append(metrics['total_responses'])\n",
    "            \n",
    "            # Flow from API to success/failure\n",
    "            successful = metrics['total_responses'] - metrics['error_count']\n",
    "            failed = metrics['error_count']\n",
    "            \n",
    "            if successful > 0:\n",
    "                sources.append(node_indices[api_name])\n",
    "                targets.append(node_indices['Successful Output'])\n",
    "                values.append(successful)\n",
    "            \n",
    "            if failed > 0:\n",
    "                sources.append(node_indices[api_name])\n",
    "                targets.append(node_indices['Failed Output'])\n",
    "                values.append(failed)\n",
    "    \n",
    "    # Create Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=node_labels,\n",
    "            color=[\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FECA57\", \"#2ECC71\", \"#E74C3C\"]\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=sources,\n",
    "            target=targets,\n",
    "            value=values,\n",
    "            color=[\"rgba(255,107,107,0.6)\" if i < len(api_metrics) else \"rgba(46,204,113,0.6)\" \n",
    "                   if targets[i] == node_indices['Successful Output'] else \"rgba(231,76,60,0.6)\"\n",
    "                   for i in range(len(sources))]\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"🌊 API Processing Flow - Sankey Diagram\",\n",
    "        font_size=12,\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(\"✅ Sankey diagram created!\")\n",
    "else:\n",
    "    print(\"⚠️  No API data available for Sankey diagram\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Analysis with N-grams\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def extract_ngrams(text, n=2):\n",
    "    \"\"\"Extract n-grams from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "# Analyze bigrams across varieties\n",
    "variety_ngrams = {}\n",
    "for variety in stimuli['variety'].unique():\n",
    "    variety_texts = stimuli[stimuli['variety'] == variety]['text'].astype(str)\n",
    "    all_text = ' '.join(variety_texts)\n",
    "    bigrams = extract_ngrams(all_text, 2)\n",
    "    variety_ngrams[variety] = Counter(bigrams).most_common(10)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Most Common Bigrams by Variety', fontsize=16)\n",
    "\n",
    "varieties = list(variety_ngrams.keys())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "\n",
    "for i, variety in enumerate(varieties):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    bigrams = variety_ngrams[variety]\n",
    "    if bigrams:\n",
    "        bigram_words, bigram_counts = zip(*bigrams)\n",
    "        \n",
    "        axes[row, col].barh(range(len(bigram_words)), bigram_counts, color=colors[i])\n",
    "        axes[row, col].set_yticks(range(len(bigram_words)))\n",
    "        axes[row, col].set_yticklabels(bigram_words, fontsize=10)\n",
    "        axes[row, col].set_title(f'{variety} - Top Bigrams')\n",
    "        axes[row, col].set_xlabel('Frequency')\n",
    "        axes[row, col].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1f884",
   "metadata": {},
   "source": [
    "## 5. Gemini-Specific Analysis\n",
    "\n",
    "Analysis of Gemini's performance patterns and response characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a94987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini-Specific Analysis: Response Quality & Consistency\n",
    "print(\"🔬 Analyzing Gemini's Response Patterns...\")\n",
    "\n",
    "# Load Gemini responses if available\n",
    "gemini_data = None\n",
    "if 'gemini' in api_responses:\n",
    "    gemini_data = api_responses['gemini'].copy()\n",
    "    \n",
    "    # Advanced Gemini Analysis\n",
    "    gemini_data['response_quality_score'] = (\n",
    "        gemini_data['output_text'].str.len() / gemini_data['input_text'].str.len()\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Detect response patterns\n",
    "    gemini_data['has_code_switching'] = gemini_data['output_text'].str.contains(\n",
    "        r'\\\\b(el|la|de|que|en|un|una|con|por|para|finna|bout|real)\\\\b', \n",
    "        case=False, na=False\n",
    "    )\n",
    "    \n",
    "    gemini_data['response_type'] = gemini_data['output_text'].apply(lambda x: \n",
    "        'Short' if len(str(x)) < 50 else \n",
    "        'Medium' if len(str(x)) < 100 else \n",
    "        'Long'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Loaded {len(gemini_data)} Gemini responses\")\n",
    "    print(f\"📊 Response quality scores: {gemini_data['response_quality_score'].describe()}\")\n",
    "else:\n",
    "    print(\"⚠️  No Gemini data available - run data collection first\")\n",
    "\n",
    "# Gemini Response Quality Distribution\n",
    "if gemini_data is not None:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('🔬 Gemini Response Quality Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Response Quality by Variety\n",
    "    variety_quality = gemini_data.groupby('variety')['response_quality_score'].mean().sort_values(ascending=False)\n",
    "    axes[0, 0].bar(variety_quality.index, variety_quality.values, color='#4285F4')\n",
    "    axes[0, 0].set_title('Response Quality by Variety')\n",
    "    axes[0, 0].set_ylabel('Quality Score')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Response Length Distribution\n",
    "    axes[0, 1].hist(gemini_data['output_text'].str.len(), bins=30, alpha=0.7, color='#34A853')\n",
    "    axes[0, 1].set_title('Response Length Distribution')\n",
    "    axes[0, 1].set_xlabel('Characters')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # 3. Code-Switching Detection\n",
    "    cs_counts = gemini_data['has_code_switching'].value_counts()\n",
    "    axes[1, 0].pie(cs_counts.values, labels=['No Code-Switching', 'Code-Switching'], \n",
    "                   autopct='%1.1f%%', colors=['#EA4335', '#FBBC04'])\n",
    "    axes[1, 0].set_title('Code-Switching Detection')\n",
    "    \n",
    "    # 4. Response Type by Task\n",
    "    response_task = pd.crosstab(gemini_data['response_type'], gemini_data['task'])\n",
    "    response_task.plot(kind='bar', ax=axes[1, 1], color=['#4285F4', '#34A853', '#FBBC04'])\n",
    "    axes[1, 1].set_title('Response Type by Task')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Gemini quality analysis completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1662593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Gemini Visualization: Multi-dimensional Performance Analysis\n",
    "if gemini_data is not None:\n",
    "    print(\"🎨 Creating Advanced Gemini Performance Visualization...\")\n",
    "    \n",
    "    # Create a sophisticated multi-panel analysis\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Performance Heatmap by Variety and Task\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    pivot_quality = gemini_data.pivot_table(\n",
    "        values='response_quality_score', \n",
    "        index='variety', \n",
    "        columns='task', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    sns.heatmap(pivot_quality, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax1)\n",
    "    ax1.set_title('🔥 Quality Heatmap: Variety vs Task', fontweight='bold')\n",
    "    \n",
    "    # 2. Response Length vs Quality Scatter\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    scatter = ax2.scatter(\n",
    "        gemini_data['output_text'].str.len(),\n",
    "        gemini_data['response_quality_score'],\n",
    "        c=gemini_data['variety'].astype('category').cat.codes,\n",
    "        cmap='viridis',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    ax2.set_xlabel('Response Length (characters)')\n",
    "    ax2.set_ylabel('Quality Score')\n",
    "    ax2.set_title('📊 Length vs Quality Correlation', fontweight='bold')\n",
    "    \n",
    "    # 3. Response Consistency Analysis\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    consistency = gemini_data.groupby('variety')['response_quality_score'].std().sort_values(ascending=True)\n",
    "    bars = ax3.barh(consistency.index, consistency.values, color='#FF6B6B')\n",
    "    ax3.set_xlabel('Standard Deviation')\n",
    "    ax3.set_title('🎯 Response Consistency by Variety', fontweight='bold')\n",
    "    \n",
    "    # 4. Advanced Box Plot with Violin\n",
    "    ax4 = fig.add_subplot(gs[1, :2])\n",
    "    sns.violinplot(\n",
    "        data=gemini_data, \n",
    "        x='variety', \n",
    "        y='response_quality_score',\n",
    "        ax=ax4,\n",
    "        palette='Set2'\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data=gemini_data, \n",
    "        x='variety', \n",
    "        y='response_quality_score',\n",
    "        ax=ax4,\n",
    "        width=0.1,\n",
    "        boxprops={'facecolor': 'white', 'alpha': 0.8}\n",
    "    )\n",
    "    ax4.set_title('🎻 Response Quality Distribution (Violin + Box Plot)', fontweight='bold')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 5. Performance Timeline (if we have temporal data)\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    if 'id' in gemini_data.columns:\n",
    "        # Simulate timeline based on ID\n",
    "        timeline_data = gemini_data.sort_values('id')\n",
    "        ax5.plot(timeline_data['id'], timeline_data['response_quality_score'], \n",
    "                marker='o', markersize=3, alpha=0.7, color='#4285F4')\n",
    "        ax5.set_xlabel('Response ID')\n",
    "        ax5.set_ylabel('Quality Score')\n",
    "        ax5.set_title('📈 Performance Over Time', fontweight='bold')\n",
    "    \n",
    "    # 6. Code-Switching Analysis\n",
    "    ax6 = fig.add_subplot(gs[2, 0])\n",
    "    cs_analysis = gemini_data.groupby(['variety', 'has_code_switching']).size().unstack(fill_value=0)\n",
    "    cs_analysis.plot(kind='bar', ax=ax6, color=['#EA4335', '#FBBC04'])\n",
    "    ax6.set_title('🔄 Code-Switching Detection', fontweight='bold')\n",
    "    ax6.set_ylabel('Count')\n",
    "    ax6.tick_params(axis='x', rotation=45)\n",
    "    ax6.legend(['No CS', 'Has CS'])\n",
    "    \n",
    "    # 7. Response Length Distribution by Variety\n",
    "    ax7 = fig.add_subplot(gs[2, 1])\n",
    "    for variety in gemini_data['variety'].unique():\n",
    "        variety_data = gemini_data[gemini_data['variety'] == variety]['output_text'].str.len()\n",
    "        ax7.hist(variety_data, alpha=0.6, label=variety, bins=20)\n",
    "    ax7.set_xlabel('Response Length')\n",
    "    ax7.set_ylabel('Frequency')\n",
    "    ax7.set_title('📏 Length Distribution by Variety', fontweight='bold')\n",
    "    ax7.legend()\n",
    "    \n",
    "    # 8. Performance Summary Stats\n",
    "    ax8 = fig.add_subplot(gs[2, 2])\n",
    "    summary_stats = gemini_data['response_quality_score'].describe()\n",
    "    ax8.axis('off')\n",
    "    ax8.text(0.1, 0.9, '📊 Gemini Performance Summary', fontsize=14, fontweight='bold', transform=ax8.transAxes)\n",
    "    ax8.text(0.1, 0.8, f'Mean Quality: {summary_stats[\"mean\"]:.3f}', fontsize=12, transform=ax8.transAxes)\n",
    "    ax8.text(0.1, 0.7, f'Std Dev: {summary_stats[\"std\"]:.3f}', fontsize=12, transform=ax8.transAxes)\n",
    "    ax8.text(0.1, 0.6, f'Min Quality: {summary_stats[\"min\"]:.3f}', fontsize=12, transform=ax8.transAxes)\n",
    "    ax8.text(0.1, 0.5, f'Max Quality: {summary_stats[\"max\"]:.3f}', fontsize=12, transform=ax8.transAxes)\n",
    "    ax8.text(0.1, 0.4, f'Total Responses: {len(gemini_data)}', fontsize=12, transform=ax8.transAxes)\n",
    "    \n",
    "    plt.suptitle('🔬 Advanced Gemini Analysis Dashboard', fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Advanced Gemini visualization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "print(\"EDA Analysis Complete!\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Visualizations Created:\")\n",
    "print(\"  - API Performance Heatmap\")\n",
    "print(\"  - Interactive Bubble Chart\") \n",
    "print(\"  - Radar Chart for API Capabilities\")\n",
    "print(\"  - Text Analysis with N-grams\")\n",
    "print(\"  - Gemini-Specific Analysis\")\n",
    "print(\"=\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703512f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb8960d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceda45",
   "metadata": {},
   "source": [
    "ombine the eda for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b5534-2a5a-46e3-839c-7b81617af58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots look cleaner\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# 1️⃣ Length ratio by variety\n",
    "sns.barplot(data=df, x=\"variety\", y=\"length_ratio\", errorbar=None)\n",
    "plt.title(\"Average Length Ratio by Variety\")\n",
    "plt.ylabel(\"Output length ÷ Input length\")\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(data=df, x=\"variety\", y=\"token_overlap\", errorbar=None)\n",
    "plt.title(\"Token Overlap Between Input and Output by Variety\")\n",
    "plt.ylabel(\"Overlap (0–1)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2be64-7864-4588-a525-32b3e9e739f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = markers = {\n",
    "    \"AAVE\": [\"finna\", \"ion\", \"gon’\", \"tryna\"],\n",
    "    \"Spanglish\": [\"la\", \"el\", \"mi\", \"amigos\", \"vamos\"],\n",
    "    \"BrEng\": [\"flat\", \"lorry\", \"holiday\", \"lift\"],\n",
    "    \"StdEng\": []  # include it even with no markers\n",
    "}\n",
    "\n",
    "\n",
    "def marker_retention(row):\n",
    "    variety = row[\"variety\"]\n",
    "    words = set(str(row[\"output_text\"]).lower().split())\n",
    "    retained = [w for w in markers.get(variety, []) if w in words]\n",
    "    return len(retained)\n",
    "\n",
    "df[\"marker_retained\"] = df.apply(marker_retention, axis=1)\n",
    "df.groupby(\"variety\")[\"marker_retained\"].mean().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546cf41-2b1f-47ba-8020-e682f8896dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"variety\", y=\"marker_retained\", errorbar=None)\n",
    "plt.title(\"Average Dialect Marker Retention by Variety\")\n",
    "plt.ylabel(\"Markers Retained\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3382ba5-fc99-4bd0-8b5d-ad56924a6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/gemini_eda_results.csv\", index=False)\n",
    "print(\"✅ Saved EDA results to ../data/processed/gemini_eda_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
