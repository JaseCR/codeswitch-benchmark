{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489e3516",
   "metadata": {},
   "source": [
    "# Data Collection: Code-Switching Benchmark\n",
    "\n",
    "## Setup and Environment Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8169e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Status:\n",
      "  Gemini:  True\n",
      "  Cohere:  True\n",
      "  Mistral: True\n"
     ]
    }
   ],
   "source": [
    "# --- Environment Setup ---\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Go to the project root (only if needed)\n",
    "if \".env\" not in os.listdir():\n",
    "    os.chdir(\"/Users/jase/codeswitch-benchmark\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check API keys\n",
    "print(\"API Keys Status:\")\n",
    "print(f\"  Gemini:  {bool(os.getenv('GEMINI_API_KEY'))}\")\n",
    "print(f\"  Cohere:  {bool(os.getenv('COHERE_API_KEY'))}\")\n",
    "print(f\"  Mistral: {bool(os.getenv('MISTRAL_API_KEY'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b7af6",
   "metadata": {},
   "source": [
    "## Create Stimuli Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c532904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created stimuli dataset: 12 examples\n",
      "Varieties: ['AAVE' 'Spanglish' 'BrEng' 'StdEng']\n",
      "Tasks: ['paraphrase' 'explain' 'continue']\n",
      "Examples per variety: {'AAVE': 3, 'Spanglish': 3, 'BrEng': 3, 'StdEng': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>variety</th>\n",
       "      <th>task</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aave_01</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>He finna go to the store. You sliding?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aave_02</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>explain</td>\n",
       "      <td>Ion think that plan gon' work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aave_03</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>continue</td>\n",
       "      <td>We was tryna finish that yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>span_01</td>\n",
       "      <td>Spanglish</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>Vamos later, it's muy close to la tienda.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>span_02</td>\n",
       "      <td>Spanglish</td>\n",
       "      <td>explain</td>\n",
       "      <td>No entiendo bien, pero I think it's fine.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    variety        task                                       text\n",
       "0  aave_01       AAVE  paraphrase     He finna go to the store. You sliding?\n",
       "1  aave_02       AAVE     explain             Ion think that plan gon' work.\n",
       "2  aave_03       AAVE    continue         We was tryna finish that yesterday\n",
       "3  span_01  Spanglish  paraphrase  Vamos later, it's muy close to la tienda.\n",
       "4  span_02  Spanglish     explain  No entiendo bien, pero I think it's fine."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure data directory exists\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "\n",
    "# Define balanced test set across language varieties and tasks\n",
    "# Define balanced test set across language varieties and tasks\n",
    "# Updated with expanded trigger words for more useful data analysis\n",
    "stimuli_data = [\n",
    "    # African American Vernacular English (AAVE)\n",
    "    {\"id\": \"aave_01\", \"variety\": \"AAVE\", \"task\": \"paraphrase\",\n",
    "     \"text\": \"He finna go to the store. You sliding?\"},\n",
    "    {\"id\": \"aave_02\", \"variety\": \"AAVE\", \"task\": \"explain\",\n",
    "     \"text\": \"Ion think that plan gon' work.\"},\n",
    "    {\"id\": \"aave_03\", \"variety\": \"AAVE\", \"task\": \"continue\",\n",
    "     \"text\": \"We was tryna finish that yesterday\"},\n",
    "\n",
    "    # Spanglish (Spanish-English code-switching)\n",
    "    {\"id\": \"span_01\", \"variety\": \"Spanglish\", \"task\": \"paraphrase\",\n",
    "     \"text\": \"Vamos later, it's muy close to la tienda.\"},\n",
    "    {\"id\": \"span_02\", \"variety\": \"Spanglish\", \"task\": \"explain\",\n",
    "     \"text\": \"No entiendo bien, pero I think it's fine.\"},\n",
    "    {\"id\": \"span_03\", \"variety\": \"Spanglish\", \"task\": \"continue\",\n",
    "     \"text\": \"We can meet en el parque, like at 5.\"},\n",
    "\n",
    "    # British English\n",
    "    {\"id\": \"br_01\", \"variety\": \"BrEng\", \"task\": \"paraphrase\",\n",
    "     \"text\": \"Put it in the lorry outside the flat.\"},\n",
    "    {\"id\": \"br_02\", \"variety\": \"BrEng\", \"task\": \"explain\",\n",
    "     \"text\": \"Take the lift, not the stairs, to the first floor.\"},\n",
    "    {\"id\": \"br_03\", \"variety\": \"BrEng\", \"task\": \"continue\",\n",
    "     \"text\": \"We're off on holiday next week, fancy it?\"},\n",
    "\n",
    "    # Standard English (control group)\n",
    "    {\"id\": \"std_01\", \"variety\": \"StdEng\", \"task\": \"paraphrase\",\n",
    "     \"text\": \"He is about to head out. Are you coming?\"},\n",
    "    {\"id\": \"std_02\", \"variety\": \"StdEng\", \"task\": \"explain\",\n",
    "     \"text\": \"Please explain this in simple terms.\"},\n",
    "    {\"id\": \"std_03\", \"variety\": \"StdEng\", \"task\": \"continue\",\n",
    "     \"text\": \"We should wrap this up and send it.\"},\n",
    "]\n",
    "\n",
    "# Create and save stimuli dataset\n",
    "stimuli = pd.DataFrame(stimuli_data)\n",
    "stimuli.to_csv(\"../data/raw/stimuli.csv\", index=False)\n",
    "\n",
    "print(f\"Created stimuli dataset: {len(stimuli)} examples\")\n",
    "print(f\"Varieties: {stimuli['variety'].unique()}\")\n",
    "print(f\"Tasks: {stimuli['task'].unique()}\")\n",
    "print(f\"Examples per variety: {stimuli['variety'].value_counts().to_dict()}\")\n",
    "stimuli.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f178394",
   "metadata": {},
   "source": [
    "## Setup Gemini API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26946fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jase/codeswitch-benchmark/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API configured successfully\n"
     ]
    }
   ],
   "source": [
    "# === Gemini API Setup ===\n",
    "# Initialize and test Gemini connection\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "\n",
    "def query_gemini(prompt: str, max_retries: int = 3):\n",
    "    \"\"\"Send a prompt to Gemini and return plain text output with retry logic.\"\"\"\n",
    "    import time\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            if response.text:\n",
    "                return response.text\n",
    "            else:\n",
    "                print(f\"Empty response from Gemini (attempt {attempt + 1})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying Gemini (attempt {attempt + 1}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                return f\"ERROR: Failed after {max_retries} attempts: {e}\"\n",
    "    return None\n",
    "\n",
    "print(\"Gemini API configured successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac40544",
   "metadata": {},
   "source": [
    "## Collect Gemini Responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f965b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting responses from Gemini...\n",
      "Processing 12 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini API calls:   0%|          | 0/12 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759347825.470664   67540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "Gemini API calls: 100%|██████████| 12/12 [02:40<00:00, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Gemini responses: 12 examples\n",
      "Successful responses: 12/12 (100.0%)\n",
      "Variety distribution: {'AAVE': 3, 'Spanglish': 3, 'BrEng': 3, 'StdEng': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>variety</th>\n",
       "      <th>task</th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aave_01</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>He finna go to the store. You sliding?</td>\n",
       "      <td>Here are a few ways to paraphrase or continue ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aave_02</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>explain</td>\n",
       "      <td>Ion think that plan gon' work.</td>\n",
       "      <td>Here are a few options, both paraphrasing and ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aave_03</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>continue</td>\n",
       "      <td>We was tryna finish that yesterday</td>\n",
       "      <td>Okay, here are some options, trying to keep th...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>span_01</td>\n",
       "      <td>Spanglish</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>Vamos later, it's muy close to la tienda.</td>\n",
       "      <td>Here are a few ways to paraphrase or continue ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>span_02</td>\n",
       "      <td>Spanglish</td>\n",
       "      <td>explain</td>\n",
       "      <td>No entiendo bien, pero I think it's fine.</td>\n",
       "      <td>Here are a few ways to paraphrase or continue ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    variety        task                                 input_text  \\\n",
       "0  aave_01       AAVE  paraphrase     He finna go to the store. You sliding?   \n",
       "1  aave_02       AAVE     explain             Ion think that plan gon' work.   \n",
       "2  aave_03       AAVE    continue         We was tryna finish that yesterday   \n",
       "3  span_01  Spanglish  paraphrase  Vamos later, it's muy close to la tienda.   \n",
       "4  span_02  Spanglish     explain  No entiendo bien, pero I think it's fine.   \n",
       "\n",
       "                                         output_text  success  \n",
       "0  Here are a few ways to paraphrase or continue ...     True  \n",
       "1  Here are a few options, both paraphrasing and ...     True  \n",
       "2  Okay, here are some options, trying to keep th...     True  \n",
       "3  Here are a few ways to paraphrase or continue ...     True  \n",
       "4  Here are a few ways to paraphrase or continue ...     True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stimuli and collect responses from Gemini\n",
    "stimuli = pd.read_csv(\"../data/raw/stimuli.csv\")\n",
    "responses = []\n",
    "\n",
    "print(\"Collecting responses from Gemini...\")\n",
    "print(f\"Processing {len(stimuli)} examples...\")\n",
    "\n",
    "for i, row in tqdm(stimuli.iterrows(), total=len(stimuli), desc=\"Gemini API calls\"):\n",
    "    prompt = f\"Paraphrase or continue this text in the same dialectal style: {row.text}\"\n",
    "    output = query_gemini(prompt)\n",
    "    \n",
    "    # Validate response quality\n",
    "    if output and not output.startswith(\"ERROR:\"):\n",
    "        responses.append({\n",
    "            \"id\": row.id,\n",
    "            \"variety\": row.variety,\n",
    "            \"task\": row.task,\n",
    "            \"input_text\": row.text,\n",
    "            \"output_text\": output,\n",
    "            \"success\": True\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Failed to get response for {row.id}: {output}\")\n",
    "        responses.append({\n",
    "            \"id\": row.id,\n",
    "            \"variety\": row.variety,\n",
    "            \"task\": row.task,\n",
    "            \"input_text\": row.text,\n",
    "            \"output_text\": output or \"ERROR: No response\",\n",
    "            \"success\": False\n",
    "        })\n",
    "\n",
    "# Save Gemini responses\n",
    "gemini_df = pd.DataFrame(responses)\n",
    "gemini_df.to_csv(\"../data/raw/gemini_responses.csv\", index=False)\n",
    "\n",
    "# Quality check\n",
    "success_count = gemini_df['success'].sum()\n",
    "print(f\"Saved Gemini responses: {len(gemini_df)} examples\")\n",
    "print(f\"Successful responses: {success_count}/{len(gemini_df)} ({success_count/len(gemini_df)*100:.1f}%)\")\n",
    "print(f\"Variety distribution: {gemini_df['variety'].value_counts().to_dict()}\")\n",
    "\n",
    "gemini_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828503d0",
   "metadata": {},
   "source": [
    "## Test Cohere API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f84c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Cohere API connection...\n",
      " Cohere Debug Agent - Full Diagnosis\n",
      "============================================================\n",
      "\n",
      "🔧 Running Comprehensive Diagnosis...\n",
      "==================================================\n",
      " Cohere Debug Agent Starting...\n",
      "==================================================\n",
      " Found project root: /Users/jase/codeswitch-benchmark\n",
      " Found .env file: /Users/jase/codeswitch-benchmark/.env\n",
      " Environment variables loaded\n",
      " API key found (prefix: SgUydfH)\n",
      " API key length: 40 characters\n",
      " Cohere client initialized\n",
      "\n",
      "🧪 Testing Cohere API Connection...\n",
      "==================================================\n",
      "\n",
      "🔄 Testing command-r-plus-08-2024...\n",
      " command-r-plus-08-2024 works: Hello!\n",
      "\n",
      " All tests passed! Cohere API is working correctly.\n",
      "\n",
      "🔧 Fixing Notebook Path Issues...\n",
      "==================================================\n",
      " Added /Users/jase/codeswitch-benchmark/src to Python path\n",
      "\n",
      "🎉 All systems operational!\n",
      "You can now use the Cohere API in your notebooks.\n",
      "Cohere API connection successful\n",
      "Collecting Cohere responses for 12 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:   8%|▊         | 1/12 [00:00<00:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  17%|█▋        | 2/12 [00:01<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  25%|██▌       | 3/12 [00:02<00:07,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  33%|███▎      | 4/12 [00:03<00:06,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  42%|████▏     | 5/12 [00:04<00:05,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  50%|█████     | 6/12 [00:04<00:04,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  58%|█████▊    | 7/12 [00:05<00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  67%|██████▋   | 8/12 [00:06<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls:  83%|████████▎ | 10/12 [00:07<00:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_03\n",
      "Error std_01: name 'attempt' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cohere API calls: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error std_02: name 'attempt' is not defined\n",
      "Error std_03: name 'attempt' is not defined\n",
      "Saved Cohere responses: 12 examples\n",
      "Successful responses: 9/12 (75.0%)\n",
      "Variety distribution: {'AAVE': 3, 'Spanglish': 3, 'BrEng': 3, 'StdEng': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Setup path for imports\n",
    "current_dir = os.getcwd()\n",
    "src_path = os.path.join('..', 'src') if current_dir.endswith('notebooks') else 'src'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Test Cohere connection and collect sample responses\n",
    "from debug_cohere import debug_cohere\n",
    "\n",
    "print(\"Testing Cohere API connection...\")\n",
    "if debug_cohere():\n",
    "    print(\"Cohere API connection successful\")\n",
    "    \n",
    "    from adapters.cohere_adapter import query_cohere\n",
    "    \n",
    "    # Collect full dataset responses\n",
    "    cohere_responses = []\n",
    "    print(f\"Collecting Cohere responses for {len(stimuli)} examples...\")\n",
    "\n",
    "    for i, row in tqdm(stimuli.iterrows(), total=len(stimuli), desc=\"Cohere API calls\"):\n",
    "        prompt = f\"Paraphrase or continue this text in the same dialectal style: {row.text}\"\n",
    "        try:\n",
    "            output = query_cohere(prompt)\n",
    "            if output and not output.startswith(\"ERROR:\"):\n",
    "                cohere_responses.append({\n",
    "                    \"id\": row.id,\n",
    "                    \"variety\": row.variety,\n",
    "                    \"task\": row.task,\n",
    "                    \"input_text\": row.text,\n",
    "                    \"output_text\": output,\n",
    "                    \"success\": True\n",
    "                })\n",
    "                print(f\"Success: {row.id}\")\n",
    "            else:\n",
    "                print(f\"Empty response for {row.id}\")\n",
    "                cohere_responses.append({\n",
    "                    \"id\": row.id,\n",
    "                    \"variety\": row.variety,\n",
    "                    \"task\": row.task,\n",
    "                    \"input_text\": row.text,\n",
    "                    \"output_text\": output or \"ERROR: Empty response\",\n",
    "                    \"success\": False\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error {row.id}: {e}\")\n",
    "            cohere_responses.append({\n",
    "                \"id\": row.id,\n",
    "                \"variety\": row.variety,\n",
    "                \"task\": row.task,\n",
    "                \"input_text\": row.text,\n",
    "                \"output_text\": f\"ERROR: {e}\",\n",
    "                \"success\": False\n",
    "            })\n",
    "\n",
    "    cohere_df = pd.DataFrame(cohere_responses)\n",
    "    cohere_df.to_csv(\"../data/raw/cohere_responses.csv\", index=False)\n",
    "    \n",
    "    # Quality check\n",
    "    success_count = cohere_df['success'].sum()\n",
    "    print(f\"Saved Cohere responses: {len(cohere_df)} examples\")\n",
    "    print(f\"Successful responses: {success_count}/{len(cohere_df)} ({success_count/len(cohere_df)*100:.1f}%)\")\n",
    "    print(f\"Variety distribution: {cohere_df['variety'].value_counts().to_dict()}\")\n",
    "    \n",
    "    cohere_df.head()\n",
    "else:\n",
    "    print(\"Cohere API connection failed. Check API key and configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c53c8c",
   "metadata": {},
   "source": [
    "## Test Mistral API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ff76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Mistral API connection...\n",
      " Mistral Debug Agent - Full Diagnosis\n",
      "============================================================\n",
      "\n",
      "🔧 Running Comprehensive Diagnosis...\n",
      "==================================================\n",
      " Mistral Debug Agent Starting...\n",
      "==================================================\n",
      " Found project root: /Users/jase/codeswitch-benchmark\n",
      " Found .env file: /Users/jase/codeswitch-benchmark/.env\n",
      " Environment variables loaded\n",
      " API key found (prefix: YWdltFw0j8)\n",
      " API key length: 32 characters\n",
      " Mistral client initialized\n",
      "\n",
      "🧪 Testing Mistral API Connection...\n",
      "==================================================\n",
      "\n",
      "🔄 Testing mistral-large-latest...\n",
      " mistral-large-latest works: Hi!\n",
      "\n",
      " All tests passed! Mistral API is working correctly.\n",
      "\n",
      "🔧 Fixing Notebook Path Issues...\n",
      "==================================================\n",
      " /Users/jase/codeswitch-benchmark/src already in Python path\n",
      "\n",
      "🎉 All systems operational!\n",
      "You can now use the Mistral API in your notebooks.\n",
      "Mistral API connection successful\n",
      "Collecting Mistral responses for 12 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:   8%|▊         | 1/12 [00:02<00:30,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  17%|█▋        | 2/12 [00:05<00:24,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  25%|██▌       | 3/12 [00:07<00:22,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: aave_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  33%|███▎      | 4/12 [00:09<00:17,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  42%|████▏     | 5/12 [00:11<00:15,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  50%|█████     | 6/12 [00:14<00:14,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: span_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  58%|█████▊    | 7/12 [00:15<00:10,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  67%|██████▋   | 8/12 [00:17<00:07,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  75%|███████▌  | 9/12 [00:18<00:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: br_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  83%|████████▎ | 10/12 [00:19<00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: std_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls:  92%|█████████▏| 11/12 [00:21<00:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: std_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral API calls: 100%|██████████| 12/12 [00:22<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: std_03\n",
      "Saved Mistral responses: 12 examples\n",
      "Successful responses: 12/12 (100.0%)\n",
      "Variety distribution: {'AAVE': 3, 'Spanglish': 3, 'BrEng': 3, 'StdEng': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from debug_mistral import debug_mistral\n",
    "\n",
    "print(\"Testing Mistral API connection...\")\n",
    "if debug_mistral():\n",
    "    print(\"Mistral API connection successful\")\n",
    "    \n",
    "    from adapters.mistral_adapter import query_mistral\n",
    "    \n",
    "    # Collect full dataset responses\n",
    "    mistral_responses = []\n",
    "    print(f\"Collecting Mistral responses for {len(stimuli)} examples...\")\n",
    "\n",
    "    for i, row in tqdm(stimuli.iterrows(), total=len(stimuli), desc=\"Mistral API calls\"):\n",
    "        prompt = f\"Paraphrase or continue this text in the same dialectal style: {row.text}\"\n",
    "        try:\n",
    "            output = query_mistral(prompt)\n",
    "            if output and not output.startswith(\"ERROR:\"):\n",
    "                mistral_responses.append({\n",
    "                    \"id\": row.id,\n",
    "                    \"variety\": row.variety,\n",
    "                    \"task\": row.task,\n",
    "                    \"input_text\": row.text,\n",
    "                    \"output_text\": output,\n",
    "                    \"success\": True\n",
    "                })\n",
    "                print(f\"Success: {row.id}\")\n",
    "            else:\n",
    "                print(f\"Empty response for {row.id}\")\n",
    "                mistral_responses.append({\n",
    "                    \"id\": row.id,\n",
    "                    \"variety\": row.variety,\n",
    "                    \"task\": row.task,\n",
    "                    \"input_text\": row.text,\n",
    "                    \"output_text\": output or \"ERROR: Empty response\",\n",
    "                    \"success\": False\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error {row.id}: {e}\")\n",
    "            mistral_responses.append({\n",
    "                \"id\": row.id,\n",
    "                \"variety\": row.variety,\n",
    "                \"task\": row.task,\n",
    "                \"input_text\": row.text,\n",
    "                \"output_text\": f\"ERROR: {e}\",\n",
    "                \"success\": False\n",
    "            })\n",
    "\n",
    "    mistral_df = pd.DataFrame(mistral_responses)\n",
    "    mistral_df.to_csv(\"../data/raw/mistral_responses.csv\", index=False)\n",
    "    \n",
    "    # Quality check\n",
    "    success_count = mistral_df['success'].sum()\n",
    "    print(f\"Saved Mistral responses: {len(mistral_df)} examples\")\n",
    "    print(f\"Successful responses: {success_count}/{len(mistral_df)} ({success_count/len(mistral_df)*100:.1f}%)\")\n",
    "    print(f\"Variety distribution: {mistral_df['variety'].value_counts().to_dict()}\")\n",
    "    \n",
    "    mistral_df.head()\n",
    "else:\n",
    "    print(\"Mistral API connection failed. Check API key and configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7cf56",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4e597",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d277348d",
   "metadata": {},
   "source": [
    "## Data Collection Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8a1adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Collection Summary ===\n",
      "Stimuli dataset: 12 examples\n",
      "Varieties: ['AAVE', 'Spanglish', 'BrEng', 'StdEng']\n",
      "Tasks: ['paraphrase', 'explain', 'continue']\n",
      "\n",
      "Collected model responses:\n",
      "  Mistral: 12 examples (12 successful)\n",
      "  Gemini: 12 examples (12 successful)\n",
      "  Cohere: 12 examples (9 successful)\n",
      "\n",
      "Data collection complete! Ready for analysis in notebook 02.\n"
     ]
    }
   ],
   "source": [
    "# Summary of collected data\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=== Data Collection Summary ===\")\n",
    "print(f\"Stimuli dataset: {len(stimuli)} examples\")\n",
    "print(f\"Varieties: {list(stimuli['variety'].unique())}\")\n",
    "print(f\"Tasks: {list(stimuli['task'].unique())}\")\n",
    "print()\n",
    "\n",
    "# Check which model response files exist\n",
    "response_files = glob.glob(\"../data/raw/*_responses.csv\")\n",
    "print(\"Collected model responses:\")\n",
    "for file_path in response_files:\n",
    "    model_name = os.path.basename(file_path).replace(\"_responses.csv\", \"\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        success_count = df['success'].sum() if 'success' in df.columns else len(df)\n",
    "        print(f\"  {model_name.title()}: {len(df)} examples ({success_count} successful)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {model_name.title()}: Error reading file - {e}\")\n",
    "\n",
    "print()\n",
    "print(\"Data collection complete! Ready for analysis in notebook 02.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
